{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pathlib\nfrom time import time\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import (Dense, Conv2D, Flatten, Dropout,\n                                     MaxPooling2D, Activation, BatchNormalization)\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-17T15:15:22.481746Z","iopub.execute_input":"2021-08-17T15:15:22.482067Z","iopub.status.idle":"2021-08-17T15:15:26.573016Z","shell.execute_reply.started":"2021-08-17T15:15:22.481993Z","shell.execute_reply":"2021-08-17T15:15:26.572201Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Load data","metadata":{}},{"cell_type":"code","source":"PATH = '../input/train-val-test-tcga-coad-msi-mss/tcga_coad_msi_mss/'\ntrain_dir = os.path.join(PATH, 'train')\nval_dir = os.path.join(PATH, 'val')\ntest_dir = os.path.join(PATH, 'test')","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-08-17T15:15:26.575276Z","iopub.execute_input":"2021-08-17T15:15:26.575529Z","iopub.status.idle":"2021-08-17T15:15:26.584773Z","shell.execute_reply.started":"2021-08-17T15:15:26.575505Z","shell.execute_reply":"2021-08-17T15:15:26.583950Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Set up variables for pre-processing\nbatch_size = 64\nepochs = 5\nIMG_HEIGHT = 224\nIMG_WIDTH = 224","metadata":{"execution":{"iopub.status.busy":"2021-08-17T15:15:26.586647Z","iopub.execute_input":"2021-08-17T15:15:26.587091Z","iopub.status.idle":"2021-08-17T15:15:26.593140Z","shell.execute_reply.started":"2021-08-17T15:15:26.587052Z","shell.execute_reply":"2021-08-17T15:15:26.590784Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"model = VGG16(include_top=False)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-17T15:15:26.595056Z","iopub.execute_input":"2021-08-17T15:15:26.595477Z","iopub.status.idle":"2021-08-17T15:15:29.359792Z","shell.execute_reply.started":"2021-08-17T15:15:26.595439Z","shell.execute_reply":"2021-08-17T15:15:29.358922Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58892288/58889256 [==============================] - 0s 0us/step\nModel: \"vgg16\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, None, None, 3)]   0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n=================================================================\nTotal params: 14,714,688\nTrainable params: 14,714,688\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Data Augmentation","metadata":{}},{"cell_type":"code","source":"train_image_generator = ImageDataGenerator(rescale = 1./255,\n                                           rotation_range = 45,\n                                           width_shift_range = 0.20,\n                                           height_shift_range = 0.20,\n                                           horizontal_flip = True,\n                                           zoom_range = 0.5)\n\nval_image_generator = ImageDataGenerator(rescale = 1./255)\n\ntrain_data_gen = train_image_generator.flow_from_directory(batch_size = batch_size,\n                                                           directory = train_dir,\n                                                           class_mode = 'binary')\n\nval_data_gen = val_image_generator.flow_from_directory(batch_size = batch_size,\n                                                       directory = val_dir,\n                                                       class_mode = 'binary')","metadata":{"execution":{"iopub.status.busy":"2021-08-17T15:15:29.360989Z","iopub.execute_input":"2021-08-17T15:15:29.361358Z","iopub.status.idle":"2021-08-17T15:23:11.531558Z","shell.execute_reply.started":"2021-08-17T15:15:29.361319Z","shell.execute_reply":"2021-08-17T15:23:11.530015Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Found 153849 images belonging to 2 classes.\nFound 19230 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Convolutional Neural Network","metadata":{}},{"cell_type":"code","source":"def create_model(input_shape, optimizer='adam', fine_tune=2):\n    \"\"\"\n    Compiles a model integrated with VGG16 pretrained layers\n    \n    input_shape: tuple - the shape of input images (width, height, channels)\n    n_classes: int - number of classes for the output layer\n    optimizer: string - instantiated optimizer to use for training. Defaults to 'RMSProp'\n    fine_tune: int - The number of pre-trained layers to unfreeze.\n                If set to 0, all pretrained layers will freeze during training\n    \"\"\"\n    \n    conv_base = VGG16(include_top=False,\n                     weights='imagenet', \n                     input_shape=input_shape)\n    \n \n    if fine_tune > 0:\n        for layer in conv_base.layers[:-fine_tune]:\n            layer.trainable = False\n    else:\n        for layer in conv_base.layers:\n            layer.trainable = False\n\n\n    top_model = conv_base.output\n    top_model = Flatten(name=\"flatten\")(top_model)\n    top_model = Dense(4096, activation='relu')(top_model)\n    top_model = Dense(1072, activation='relu')(top_model)\n    top_model = Dropout(0.2)(top_model)\n    output_layer = Dense(1, activation='sigmoid')(top_model)\n    \n    model = Model(inputs=conv_base.input, outputs=output_layer)\n\n    model.compile(optimizer='adam', \n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-08-17T15:23:11.532842Z","iopub.execute_input":"2021-08-17T15:23:11.533170Z","iopub.status.idle":"2021-08-17T15:23:11.543369Z","shell.execute_reply.started":"2021-08-17T15:23:11.533141Z","shell.execute_reply":"2021-08-17T15:23:11.540063Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model","metadata":{"execution":{"iopub.status.busy":"2021-08-17T15:23:11.544832Z","iopub.execute_input":"2021-08-17T15:23:11.545392Z","iopub.status.idle":"2021-08-17T15:23:11.555960Z","shell.execute_reply.started":"2021-08-17T15:23:11.545354Z","shell.execute_reply":"2021-08-17T15:23:11.555079Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"input_shape = (224, 224, 3)\noptim_1 = Adam(learning_rate=0.0001)\nvgg_model = create_model(input_shape, optim_1, fine_tune=2)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T15:23:11.558622Z","iopub.execute_input":"2021-08-17T15:23:11.559104Z","iopub.status.idle":"2021-08-17T15:23:11.886856Z","shell.execute_reply.started":"2021-08-17T15:23:11.559064Z","shell.execute_reply":"2021-08-17T15:23:11.886031Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Model Training","metadata":{}},{"cell_type":"code","source":"history = vgg_model.fit(train_data_gen,\n              batch_size=64,\n              epochs=20,\n              validation_data=val_data_gen,\n              steps_per_epoch=50,\n              validation_steps=val_data_gen.samples // 64)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T15:23:11.888305Z","iopub.execute_input":"2021-08-17T15:23:11.888633Z","iopub.status.idle":"2021-08-17T15:23:26.376199Z","shell.execute_reply.started":"2021-08-17T15:23:11.888596Z","shell.execute_reply":"2021-08-17T15:23:26.373638Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-bc4c9aab5065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m               validation_steps=val_data_gen.samples // 64)\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m:  Input to reshape is a tensor with 2097152 values, but the requested shape requires a multiple of 25088\n\t [[node model/flatten/Reshape (defined at <ipython-input-9-bc4c9aab5065>:6) ]] [Op:__inference_train_function_1845]\n\nFunction call stack:\ntrain_function\n"],"ename":"InvalidArgumentError","evalue":" Input to reshape is a tensor with 2097152 values, but the requested shape requires a multiple of 25088\n\t [[node model/flatten/Reshape (defined at <ipython-input-9-bc4c9aab5065>:6) ]] [Op:__inference_train_function_1845]\n\nFunction call stack:\ntrain_function\n","output_type":"error"}]},{"cell_type":"markdown","source":"### Visualize Loss and Accuracy","metadata":{}},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(5)\n\nplt.figure(figsize = (8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(epochs_range, acc, label = 'Training Accuracy')\nplt.plot(epochs_range, val_acc, label = 'Validation Accuracy')\nplt.legend(loc = 'lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(epochs_range, loss, label = 'Training Loss')\nplt.plot(epochs_range, val_loss, label = 'Validation Loss')\nplt.legend(loc = 'upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-17T15:23:26.377140Z","iopub.status.idle":"2021-08-17T15:23:26.377532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation","metadata":{}},{"cell_type":"code","source":"test_image_generator = ImageDataGenerator(rescale = 1./255)\ntest_data_gen = test_image_generator.flow_from_directory(batch_size = batch_size,\n                                                         directory = test_dir,\n                                                         shuffle = False,\n                                                         target_size = (IMG_HEIGHT, IMG_WIDTH),\n                                                         class_mode = 'binary')\n\nresult = model.evaluate(test_data_gen)\nprint('Test Loss: ', result[0])\nprint('Test Accuracy: ', result[4])","metadata":{"execution":{"iopub.status.busy":"2021-08-17T15:23:26.378547Z","iopub.status.idle":"2021-08-17T15:23:26.379025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image, test_label = next(test_data_gen)\n\npredicted_batch = model.predict(test_image)\npredicted_id = np.argmax(predicted_batch, axis = -1)\npredicted_label_batch = class_names[predicted_id]\n\nplt.figure(figsize = (10, 10))\nplt.subplots_adjust(hspace = 0.5)\nfor n in range(30):\n    plt.subplot(6, 5, n + 1)\n    plt.imshow(test_image[n])\n    color = \"blue\" if predicted_id[n] == test_label[n] else \"red\"\n    plt.title(predicted_label_batch[n], color = color)\n    plt.axis('off')\n_ = plt.suptitle(\"CNN Predictions (blue: correct, red: incorrect)\")","metadata":{"execution":{"iopub.status.busy":"2021-08-17T15:23:26.379974Z","iopub.status.idle":"2021-08-17T15:23:26.380519Z"},"trusted":true},"execution_count":null,"outputs":[]}]}